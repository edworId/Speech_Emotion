<h1 align="center"> Speech Emotion Detection üéôÔ∏è </h1>

<p align="center">
  <img src="http://img.shields.io/static/v1?label=STATUS&message=COMPLETE&color=GREEN&style=for-the-badge"/>
</p>


Detect emotions in audio with this speech emotion detection project. The system analyzes voice recordings and categorizes them into emotions. Utilizing the RAVDESS dataset, the model is trained to recognize a wide range of emotional expressions using mel spectograms features.

### Mel Spectrogram and Emotion Detection

In the realm of audio signal processing, Mel spectrogram stands as a crucial tool for extracting meaningful features from sound waves. The Mel spectrogram is a visual representation of the spectrum of frequencies in an audio signal, but with an emphasis on how the human ear perceives these frequencies.

<p align="center">
  <img width="400" src="https://librosa.org/doc/main/_images/librosa-feature-melspectrogram-1.png"/>
</p>


Here's how it plays a pivotal role in the detection of emotions:

#### **Frequency Representation:**
   - Mel spectrograms divide the audio signal into multiple frequency bands, mimicking the non-linear frequency response of the human ear. This ensures that the representation aligns more closely with how humans perceive different pitches.

#### **Feature Extraction:**
   - Utilizing Mel spectrograms aids in capturing essential features from the audio, highlighting nuances that are crucial for emotion detection. These features include variations in pitch, intensity, and duration that are indicative of different emotional states.

In this speech emotion detection project, Mel spectrograms are employed as a key component in the feature extraction pipeline. This enables the model to effectively analyze voice recordings and categorize them into emotions creating a robust and accurate system for emotional expression recognition.


### Emotions:
Neutral, Calm, Happy, Sad, Angry, Fear, Disgust, Surprised

#### Access the RAVDESS Dataset:
[RAVDESS Dataset](https://zenodo.org/record/1188976)

<h1 align="center"> Interface Preview </h1>
<p align="center">
  <img width="300" title="RECORD AND DETECT" src="https://github.com/edworId/speech_emotion/blob/main/design.jpg"/>
</p>

<h6 align="center">Built using Python and the tkinter library for GUI development.</h6>

### Link to Access Data and Model:
[Data and Model](https://drive.google.com/drive/folders/13n72lplx3pcL9vReyHGVAO5zOdhtaChZ?usp=sharing)

#### Clone the Repository:
```bash
git clone git@github.com:edworId/speech_emotion.git
```

<h1> Autores </h1>

| [<img src="https://avatars.githubusercontent.com/u/110691832?s=400&u=e671447386d38975c165bff78b715ea80549c069&v=4" width=115><br><sub>Edmundo Lopes Silva</sub>](https://github.com/edworId) |  
| :---: |

<p align="center">
<img src="https://img.shields.io/badge/Python-14354C?style=for-the-badge&logo=python&logoColor=white"/>
</p>





